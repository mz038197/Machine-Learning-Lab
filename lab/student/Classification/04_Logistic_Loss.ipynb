{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28844c5a",
   "metadata": {},
   "source": [
    "# 邏輯迴歸及其損失函數 (Logistic Loss)\n",
    "\n",
    "在這個實驗中，你將會：\n",
    "\n",
    "- 探索為什麼平方誤差損失不適用於邏輯迴歸\n",
    "\n",
    "- 探索邏輯迴歸的損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ip = get_ipython()\n",
    "    if ip is not None:\n",
    "        try:\n",
    "            ip.run_line_magic('matplotlib', 'widget')\n",
    "        except Exception:\n",
    "            ip.run_line_magic('matplotlib', 'inline')\n",
    "            print(\"Colab 不支援 matplotlib widget\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#region 匯入資料\n",
    "def find_repo_root(marker=\"README.md\"):\n",
    "    cur = Path.cwd()\n",
    "    while cur != cur.parent:  # 防止無限迴圈，到達檔案系統根目錄就停\n",
    "        if (cur / marker).exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return None\n",
    "\n",
    "\n",
    "def import_data_from_github():\n",
    "    import os, urllib.request, pathlib, shutil\n",
    "    \n",
    "    def isRunningInColab() -> bool:\n",
    "        return \"google.colab\" in sys.modules\n",
    "\n",
    "    def isRunningInJupyterLab() -> bool:\n",
    "        try:\n",
    "            import jupyterlab\n",
    "            return True\n",
    "        except ImportError:\n",
    "            return False\n",
    "        \n",
    "    def detect_env():\n",
    "        from IPython import get_ipython\n",
    "        if isRunningInColab():\n",
    "            return \"Colab\"\n",
    "        elif isRunningInJupyterLab():\n",
    "            return \"JupyterLab\"\n",
    "        elif \"notebook\" in str(type(get_ipython())).lower():\n",
    "            return \"Jupyter Notebook\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "    def get_utils_dir(env): \n",
    "        if env == \"Colab\": \n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return \"/content/utils\"\n",
    "        else:\n",
    "            return Path.cwd() / \"utils\"\n",
    "\n",
    "    env = detect_env()\n",
    "    UTILS_DIR = get_utils_dir(env)\n",
    "    REPO_DIR = \"Machine-Learning-Lab\"\n",
    "\n",
    "    #shutil.rmtree(UTILS_DIR, ignore_errors=True)\n",
    "    os.makedirs(UTILS_DIR, exist_ok=True)\n",
    "\n",
    "    BASE = f\"https://raw.githubusercontent.com/mz038197/{REPO_DIR}/main\"\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/lab_utils_common_classification.py\", f\"{UTILS_DIR}/lab_utils_common_classification.py\")\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/plt_logistic_loss.py\", f\"{UTILS_DIR}/plt_logistic_loss.py\")\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/deeplearning.mplstyle\", f\"{UTILS_DIR}/deeplearning.mplstyle\")\n",
    "\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "\n",
    "if repo_root is None:\n",
    "    import_data_from_github()\n",
    "    repo_root = Path.cwd()\n",
    "    \n",
    "\n",
    "os.chdir(repo_root)\n",
    "print(f\"✅ 切換工作目錄至 {Path.cwd()}\")\n",
    "sys.path.append(str(repo_root)) if str(repo_root) not in sys.path else None\n",
    "print(f\"✅ 加入到系統路徑\")\n",
    "\n",
    "from utils.plt_logistic_loss import  plt_logistic_cost, plt_two_logistic_loss_curves, plt_simple_example\n",
    "from utils.plt_logistic_loss import soup_bowl, plt_logistic_squared_error\n",
    "\n",
    "plt.style.use('utils/deeplearning.mplstyle')\n",
    "print(\"✅ 匯入模組及設定繪圖樣式\")\n",
    "#endregion 匯入資料\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1a915",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aeac05",
   "metadata": {},
   "source": [
    "## 邏輯迴歸可以用平方誤差嗎？\n",
    "\n",
    "回想在 **線性** 迴歸中，我們使用的是 **平方誤差成本函數**：\n",
    "\n",
    "單一變數時，平方誤差成本的式子為：\n",
    "\n",
    "  $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 \\tag{1}$$ \n",
    " \n",
    "其中 \n",
    "\n",
    "  $$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea0b51",
   "metadata": {},
   "source": [
    "回想一下，平方誤差成本有個很好的性質：沿著成本函數的導數（梯度）方向下降，會走到最小值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a06067",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_bowl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858711f",
   "metadata": {},
   "source": [
    "這個成本函數在線性迴歸中表現良好，因此也很自然會想把它用在邏輯迴歸上。\n",
    "\n",
    "不過，如上圖所示，現在的 $f_{w,b}(x)$ 包含一個非線性成分——sigmoid 函數：$f_{w,b}(x^{(i)}) = sigmoid(wx^{(i)} + b )$。\n",
    "\n",
    "我們試著把平方誤差成本套用到先前實驗的例子上（這次加入 sigmoid）。\n",
    "\n",
    "以下是訓練資料："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0., 1, 2, 3, 4, 5],dtype=np.longdouble)\n",
    "y_train = np.array([0,  0, 0, 1, 1, 1],dtype=np.longdouble)\n",
    "plt_simple_example(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5db24",
   "metadata": {},
   "source": [
    "現在，讓我們用 **平方誤差成本** 來畫出成本的曲面圖：\n",
    "\n",
    "  $$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2 $$ \n",
    " \n",
    "其中 \n",
    "\n",
    "  $$f_{w,b}(x^{(i)}) = sigmoid(wx^{(i)} + b )$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt_logistic_squared_error(x_train,y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a82455",
   "metadata": {},
   "source": [
    "雖然這張圖很有趣，但上面的曲面遠不如線性迴歸的「湯碗（soup bowl）」那樣平滑！\n",
    "\n",
    "邏輯迴歸需要更符合其非線性特性的成本函數。這會從 **損失函數（loss function）** 開始，下面會說明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c9648d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30969a",
   "metadata": {},
   "source": [
    "## 邏輯損失函數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6337a3",
   "metadata": {},
   "source": [
    "邏輯迴歸（Logistic Regression）使用更適合**分類**任務的損失函數，因為目標值是 0 或 1，而不是任意實數。\n",
    "\n",
    ">**名詞定義：** 在本課程中，採用以下定義：  \n",
    "**Loss（損失）**：衡量「單一樣本」的預測與目標值之差。  \n",
    "**Cost（成本）**：衡量「整個訓練集」的損失彙總結果。\n",
    "\n",
    "定義如下：\n",
    "\n",
    "- $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ 表示單一資料點的損失（loss）：\n",
    "\n",
    "\\begin{equation}\n",
    "  loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = \\begin{cases}\n",
    "    - \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) & \\text{if $y^{(i)}=1$}\\\\\n",
    "    - \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) & \\text{if $y^{(i)}=0$}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "- $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ 是模型的預測值，而 $y^{(i)}$ 是目標值（標記）。\n",
    "\n",
    "- $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot\\mathbf{x}^{(i)}+b)$，其中 $g$ 是 sigmoid 函數。\n",
    "\n",
    "- 記號慣例：`log` 表示自然對數（natural logarithm）。\n",
    "\n",
    "這個損失函數的關鍵特色在於它使用了兩條不同的曲線：當目標為 0（$y=0$）時使用一條，當目標為 1（$y=1$）時使用另一條。\n",
    "\n",
    "把兩者合併後，就能呈現我們希望的行為：當預測與目標一致時損失為 0；當預測偏離目標時，損失會快速增大。請看下圖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_two_logistic_loss_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e49684",
   "metadata": {},
   "source": [
    "把兩條曲線合併後，外觀會有點像平方誤差損失的二次曲線。注意，x 軸是 $f_{\\mathbf{w},b}$，也就是 sigmoid 的輸出；而 sigmoid 的輸出嚴格介於 0 與 1 之間。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15415ba5",
   "metadata": {},
   "source": [
    "上面的損失函數可以改寫成較容易實作的形式：\n",
    "\n",
    "$$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)$$\n",
    "\n",
    "這個式子乍看之下很嚇人，但只要記得 $y^{(i)}$ 只能取兩個值：0 或 1，就會容易許多。我們可以把它分成兩種情況來看：\n",
    "\n",
    "當 $y^{(i)} = 0$ 時，左邊那一項會被消去：\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), 0) &= (-(0) \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - 0\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\\\\n",
    "&= -\\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "而當 $y^{(i)} = 1$ 時，右邊那一項會被消去：\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), 1) &=  (-(1) \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - 1\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\\\\\n",
    "  &=  -\\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "有了這個新的邏輯損失函數後，我們就能把所有樣本的損失彙整起來，形成成本函數（cost function）——這會是下一個實驗的主題。\n",
    "\n",
    "現在，先來看看我們上面那個簡單例子中，「成本」對「參數」的曲線："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "cst = plt_logistic_cost(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b05f14",
   "metadata": {},
   "source": [
    "這條曲線很適合用梯度下降來最佳化！它沒有平台區、局部極小值或不連續點。注意，它不像平方誤差那樣是個「碗狀」。\n",
    "\n",
    "圖中同時畫出成本以及成本的對數，是為了讓你看清楚：當成本很小時，曲線仍然有斜率，並且會繼續下降。\n",
    "\n",
    "提醒：你可以用滑鼠旋轉上面的圖。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7de5e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a858e61",
   "metadata": {},
   "source": [
    "## 恭喜！\n",
    "\n",
    "你已經：\n",
    "\n",
    "- 確認平方誤差損失函數不適合用在分類任務\n",
    "\n",
    "- 推導並觀察了 **適合** 分類任務的邏輯損失函數。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5c619",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
