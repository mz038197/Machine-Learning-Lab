{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¸¬é©—å¯¦é©—2ï¼šå¤šè®Šé‡ç·šæ€§è¿´æ­¸ï¼ˆMultiple Linear Regressionï¼‰\n",
    "\n",
    "å»¶çºŒä¸Šä¸€ä»½ã€Œé€£é–é¤å»³åŸ·è¡Œé•·ã€çš„æƒ…å¢ƒï¼šä½ æƒ³è©•ä¼°è¦åœ¨å“ªäº›åŸå¸‚é–‹è¨­æ–°çš„åˆ†åº—ã€‚\n",
    "\n",
    "é€™æ¬¡ä¸åªçœ‹äººå£æ•¸ï¼Œé‚„æœƒåŒæ™‚è€ƒæ…®å¦ä¸€å€‹é‡è¦å› ç´ ï¼ˆä¾‹å¦‚ï¼šç•¶åœ°å¹³å‡æ”¶å…¥ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - å¥—ä»¶ï¼ˆPackagesï¼‰\n",
    "\n",
    "è«‹å…ˆåŸ·è¡Œä¸‹æ–¹å„²å­˜æ ¼å®Œæˆç’°å¢ƒè¨­å®šã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# @title **ğŸ”§ ç’°å¢ƒæº–å‚™ï¼ˆColab / æœ¬æ©Ÿçš†å¯ï¼‰**\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import sys, os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# region è³‡æ–™è¼‰å…¥\n",
    "def find_repo_root(marker=\"README.md\"):\n",
    "    cur = Path.cwd()\n",
    "    while cur != cur.parent:  # é˜²æ­¢ç„¡é™è¿´åœˆï¼Œåˆ°é”æª”æ¡ˆç³»çµ±æ ¹ç›®éŒ„å°±åœ\n",
    "        if (cur / marker).exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return None\n",
    "\n",
    "def import_data_from_github():\n",
    "    import urllib.request\n",
    "\n",
    "    def isRunningInColab() -> bool:\n",
    "        return \"google.colab\" in sys.modules\n",
    "\n",
    "    def isRunningInJupyterLab() -> bool:\n",
    "        try:\n",
    "            import jupyterlab  # noqa: F401\n",
    "            return True\n",
    "        except ImportError:\n",
    "            return False\n",
    "\n",
    "    def detect_env():\n",
    "        from IPython import get_ipython\n",
    "        if isRunningInColab():\n",
    "            return \"Colab\"\n",
    "        elif isRunningInJupyterLab():\n",
    "            return \"JupyterLab\"\n",
    "        elif \"notebook\" in str(type(get_ipython())).lower():\n",
    "            return \"Jupyter Notebook\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def get_utils_dir(env):\n",
    "        if env == \"Colab\":\n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return \"/content/utils\"\n",
    "        else:\n",
    "            return Path.cwd() / \"utils\"\n",
    "\n",
    "    def get_data_dir(env):\n",
    "        if env == \"Colab\":\n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return \"/content/data\"\n",
    "        else:\n",
    "            return Path.cwd() / \"data\"\n",
    "\n",
    "    env = detect_env()\n",
    "    UTILS_DIR = get_utils_dir(env)\n",
    "    DATA_DIR = get_data_dir(env)\n",
    "\n",
    "    REPO_DIR = \"Machine-Learning-Lab\"\n",
    "    os.makedirs(UTILS_DIR, exist_ok=True)\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "    BASE = f\"https://raw.githubusercontent.com/mz038197/{REPO_DIR}/main\"\n",
    "\n",
    "    utils_list = [\"utils.py\", \"public_tests.py\"]\n",
    "    for u in utils_list:\n",
    "        urllib.request.urlretrieve(f\"{BASE}/utils/{u}\", f\"{UTILS_DIR}/{u}\")\n",
    "\n",
    "    data_list = [\"ex1data1.txt\", \"ex1data2.txt\"]\n",
    "    for d in data_list:\n",
    "        urllib.request.urlretrieve(f\"{BASE}/data/{d}\", f\"{DATA_DIR}/{d}\")\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "if repo_root is None:\n",
    "    import_data_from_github()\n",
    "    repo_root = Path.cwd()\n",
    "\n",
    "os.chdir(repo_root)\n",
    "print(f\"âœ… åˆ‡æ›å·¥ä½œç›®éŒ„è‡³ {Path.cwd()}\")\n",
    "sys.path.append(str(repo_root)) if str(repo_root) not in sys.path else None\n",
    "print(\"âœ… åŠ å…¥åˆ°ç³»çµ±è·¯å¾‘\")\n",
    "\n",
    "from utils.utils import *\n",
    "\n",
    "print(\"âœ… åŒ¯å…¥æ¨¡çµ„åŠè¨­å®šç¹ªåœ–æ¨£å¼\")\n",
    "# endregion è³‡æ–™è¼‰å…¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - å¤šè®Šé‡ç·šæ€§è¿´æ­¸\n",
    "\n",
    "### 2.1 å•é¡Œèªªæ˜ï¼ˆProblem Statementï¼‰\n",
    "ä½ æ˜¯ä¸€é–“é€£é–é¤å»³çš„åŸ·è¡Œé•·ï¼Œæ­£åœ¨è©•ä¼°è¦åœ¨å“ªäº›åŸå¸‚é–‹è¨­æ–°çš„åˆ†åº—ã€‚\n",
    "\n",
    "èˆ‡å–®è®Šé‡ä¸åŒçš„æ˜¯ï¼šä½ å¸Œæœ›åŒæ™‚åˆ©ç”¨å¤šå€‹ç‰¹å¾µä¾†é æ¸¬ç²åˆ©ï¼Œä¾‹å¦‚ï¼š\n",
    "- åŸå¸‚äººå£æ•¸ï¼ˆpopulationï¼‰\n",
    "- ç•¶åœ°å¹³å‡æ”¶å…¥ï¼ˆincome proxyï¼‰\n",
    "\n",
    "ä½ çš„ç›®æ¨™æ˜¯ç”¨é€™äº›ç‰¹å¾µï¼Œé æ¸¬æ¯å€‹åŸå¸‚çš„é¤å»³å¹³å‡æ¯æœˆç²åˆ©ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 è³‡æ–™é›†ï¼ˆDatasetï¼‰\n",
    "\n",
    "è¼‰å…¥å¤šè®Šé‡è³‡æ–™é›†ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_data_multi()\n",
    "print('Type of X_train:', type(X_train))\n",
    "print('Type of y_train:', type(y_train))\n",
    "print('First row of X_train:', X_train[0])\n",
    "print('First five elements of y_train:', y_train[:5])\n",
    "\n",
    "# Scatter plots: each feature vs target\n",
    "feature_names = [\"population (10,000s)\", \"income proxy ($10,000s)\"]\n",
    "fig, axes = plt.subplots(1, X_train.shape[1], figsize=(6 * X_train.shape[1], 4), squeeze=False)\n",
    "for j in range(X_train.shape[1]):\n",
    "    ax = axes[0, j]\n",
    "    ax.scatter(X_train[:, j], y_train, marker='x', c='r', alpha=0.7)\n",
    "    xlab = feature_names[j] if j < len(feature_names) else f\"feature {j}\"\n",
    "    ax.set_xlabel(xlab)\n",
    "    ax.set_ylabel(\"profit ($10,000s)\")\n",
    "    ax.set_title(f\"{xlab} vs profit\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### è®Šæ•¸èªªæ˜\n",
    "- `X_train`ï¼šshape ç‚º (m, n) çš„ç‰¹å¾µçŸ©é™£ï¼ˆm ç­†è³‡æ–™ã€n å€‹ç‰¹å¾µï¼‰\n",
    "  - æœ¬æ¸¬é©—ä¸­ n = 2\n",
    "  - `X_train[:,0]`ï¼šåŸå¸‚äººå£ï¼ˆå–®ä½ï¼š10,000 äººï¼‰\n",
    "  - `X_train[:,1]`ï¼šç•¶åœ°å¹³å‡æ”¶å…¥æŒ‡æ¨™ï¼ˆå–®ä½ï¼š\\$10,000ï¼‰\n",
    "- `y_train`ï¼šshape ç‚º (m,) çš„æ¨™ç±¤å‘é‡\n",
    "  - æ¯æœˆç²åˆ©ï¼ˆå–®ä½ï¼š\\$10,000ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print('The shape of X_train is:', X_train.shape)\n",
    "print('The shape of y_train is:', y_train.shape)\n",
    "print('Number of training examples (m):', X_train.shape[0])\n",
    "print('Number of features (n):', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ç‰¹å¾µç¸®æ”¾ï¼ˆFeature Scalingï¼‰\n",
    "å¤šè®Šé‡ç·šæ€§è¿´æ­¸é€šå¸¸éœ€è¦åšç‰¹å¾µç¸®æ”¾ï¼ˆä¾‹å¦‚ z-score normalizationï¼‰ï¼Œè®“æ¢¯åº¦ä¸‹é™æ›´ç©©å®šã€æ”¶æ–‚æ›´å¿«ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: zscore_normalize_features\n",
    "def zscore_normalize_features(X):\n",
    "    \"\"\"Z-score normalize features.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Shape (m, n) input features\n",
    "\n",
    "    Returns:\n",
    "        X_norm (ndarray): normalized features, shape (m, n)\n",
    "        mu (ndarray): mean of each feature, shape (n,)\n",
    "        sigma (ndarray): std of each feature, shape (n,)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    mu     = np.mean(X, axis=0)                \n",
    "    sigma  = np.std(X, axis=0)                 \n",
    "    X_norm = (X - mu) / sigma      \n",
    "    ### END CODE HERE ###\n",
    "    return X_norm, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "X_norm, mu, sigma = zscore_normalize_features(X_train)\n",
    "print('mu:', mu)\n",
    "print('sigma:', sigma)\n",
    "print('First row of X_norm:', X_norm[0])\n",
    "\n",
    "from utils.public_tests import *\n",
    "zscore_normalize_features_test(zscore_normalize_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 æˆæœ¬å‡½æ•¸ï¼ˆCompute Costï¼‰\n",
    "å¤šè®Šé‡ç·šæ€§è¿´æ­¸æ¨¡å‹ï¼š\n",
    "$$f_{w,b}(\\mathbf{x}) = \\mathbf{x}\\cdot\\mathbf{w} + b$$\n",
    "\n",
    "æˆæœ¬å‡½æ•¸ï¼š\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{2m} \\sum_{i=0}^{m-1} (f_{w,b}(\\mathbf{x}^{(i)}) - y^{(i)})^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_cost_multi\n",
    "def compute_cost_multi(X, y, w, b):\n",
    "    \"\"\"Compute cost for multivariate linear regression.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Shape (m, n) features\n",
    "        y (ndarray): Shape (m,) target values\n",
    "        w (ndarray): Shape (n,) model parameters\n",
    "        b (scalar): bias parameter\n",
    "    Returns:\n",
    "        cost (float): scalar cost value\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    ### START CODE HERE ###\n",
    "    f_wb = np.dot(X, w) + b;\n",
    "    c = np.pow(f_wb - y, 2);\n",
    "    cost = np.sum(c)*(1/(2*m));\n",
    "    ### END CODE HERE ###\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(X_norm.shape[1])\n",
    "initial_b = 0.\n",
    "cost = compute_cost_multi(X_norm, y_train, initial_w, initial_b)\n",
    "print(f'Cost at initial w,b (zeros): {cost:.3f}')\n",
    "\n",
    "from utils.public_tests import *\n",
    "compute_cost_multi_test(compute_cost_multi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é æœŸè¼¸å‡ºï¼ˆExpected Outputï¼‰**ï¼š\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><b>Cost at initial w,b (zeros)</b></td>\n",
    "    <td>120.388</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 æ¢¯åº¦è¨ˆç®—ï¼ˆCompute Gradientï¼‰\n",
    "æ¢¯åº¦ï¼š\n",
    "$$\\frac{\\partial J}{\\partial b} = \\frac{1}{m}\\sum_{i=0}^{m-1} (f_{w,b}(\\mathbf{x}^{(i)})-y^{(i)})$$\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{w}} = \\frac{1}{m}\\sum_{i=0}^{m-1} (f_{w,b}(\\mathbf{x}^{(i)})-y^{(i)})\\mathbf{x}^{(i)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_gradient_multi\n",
    "def compute_gradient_multi(X, y, w, b):\n",
    "    \"\"\"Compute gradient for multivariate linear regression.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): Shape (m, n)\n",
    "        y (ndarray): Shape (m,)\n",
    "        w (ndarray): Shape (n,)\n",
    "        b (scalar)\n",
    "    Returns:\n",
    "        dj_dw (ndarray): Shape (n,)\n",
    "        dj_db (scalar)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    ### START CODE HERE ###\n",
    "    losses = np.dot(X, w) + b - y #Shape (m, 1)\n",
    "    dj_dw = np.dot(X.T, losses) * (1/m)\n",
    "    dj_db = np.sum(losses) * (1/m)\n",
    "    ### END CODE HERE ###\n",
    "    return dj_dw, dj_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "tmp_dj_dw, tmp_dj_db = compute_gradient_multi(X_norm, y_train, initial_w, initial_b)\n",
    "print('dj_dw at initial w,b (zeros):', tmp_dj_dw)\n",
    "print('dj_db at initial w,b (zeros):', tmp_dj_db)\n",
    "\n",
    "from utils.public_tests import *\n",
    "compute_gradient_multi_test(compute_gradient_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é æœŸè¼¸å‡ºï¼ˆExpected Outputï¼‰**ï¼š\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><b>dj_dw at initial w,b (zeros)</b></td>\n",
    "    <td>[-5.13108179 -4.88920085]</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><b>dj_db at initial w,b (zeros)</b></td>\n",
    "    <td>-14.110691489361702</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰\n",
    "ä»¥ä¸‹æä¾›ä¸€å€‹æ‰¹æ¬¡æ¢¯åº¦ä¸‹é™ï¼ˆbatch gradient descentï¼‰çš„åƒè€ƒå¯¦ä½œï¼ˆéè©•åˆ†ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multi(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    \"\"\"Batch gradient descent for multivariate linear regression.\"\"\"\n",
    "    m = X.shape[0]\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(X, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        if i < 100000:\n",
    "            J_history.append(cost_function(X, y, w, b))\n",
    "        if i % max(1, math.ceil(num_iters / 10)) == 0:\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}\")\n",
    "    return w, b, J_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(X_norm.shape[1])\n",
    "initial_b = 0.\n",
    "alpha = 0.005\n",
    "iterations = 1000\n",
    "\n",
    "w, b, J_hist = gradient_descent_multi(X_norm, y_train, initial_w, initial_b,\n",
    "                                     compute_cost_multi, compute_gradient_multi,\n",
    "                                     alpha, iterations)\n",
    "print('w,b found by gradient descent:', w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é æœŸè¼¸å‡ºï¼ˆExpected Outputï¼‰**ï¼š\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><b>w,b found by gradient descent</b></td>\n",
    "    <td>[4.05204514 3.72240328] 14.0167993915659</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥è‘—ï¼Œæˆ‘å€‘æœƒæŠŠé€™äº›é æ¸¬å€¼ç•«å‡ºä¾†ï¼Œèˆ‡åŸå§‹è³‡æ–™é»ä¸€èµ·é¡¯ç¤ºï¼Œä»¥è§€å¯Ÿç·šæ€§æ“¬åˆçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs actual on training set\n",
    "y_pred = np.dot(X_norm, w) + b\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_train, y_pred, alpha=0.7)\n",
    "lims = [min(y_train.min(), y_pred.min()), max(y_train.max(), y_pred.max())]\n",
    "plt.plot(lims, lims, 'k--', linewidth=2)\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"Actual profit ($10,000s)\")\n",
    "plt.ylabel(\"Predicted profit ($10,000s)\")\n",
    "plt.title(\"Predicted vs Actual (training set)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ­å–œä½ å®Œæˆé€™å€‹å¤šè®Šé‡ç·šæ€§è¿´æ­¸çš„æ¸¬é©—å¯¦é©—**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é€²éšï¼šç”¨å­¸åˆ°çš„åƒæ•¸åšé æ¸¬\n",
    "è©¦è‘—è¼¸å…¥ä¸€å€‹æ–°åŸå¸‚çš„ç‰¹å¾µï¼ˆäººå£ã€å¹³å‡æ”¶å…¥ï¼‰ï¼Œä¸¦ç”¨ä½ å­¸åˆ°çš„ `(w,b)` é æ¸¬ç²åˆ©ã€‚\n",
    "æç¤ºï¼šè¦å…ˆç”¨åŒä¸€çµ„ `mu`ã€`sigma` åš z-score normalizationï¼Œå†ä¸Ÿé€²æ¨¡å‹ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
