{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d987328e",
   "metadata": {},
   "source": [
    "# **特徵縮放與學習率（多變量）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca44d27",
   "metadata": {},
   "source": [
    "## 目標\n",
    "在本實驗中，你將：\n",
    "- 使用在前一個實驗中建立的多變量相關函式\n",
    "- 在具有多個特徵的資料集上執行梯度下降（Gradient Descent）\n",
    "- 探索「學習率 α」對梯度下降的影響\n",
    "- 利用 z-score 正規化進行特徵縮放，以提升梯度下降的效能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897bed3d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a835c",
   "metadata": {},
   "source": [
    "## 工具\n",
    "你將會使用上一個實驗中撰寫的函式，以及 `matplotlib` 與 `NumPy` 等套件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# region 資料載入\n",
    "import sys, os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_repo_root(marker=\"README.md\"):\n",
    "    cur = Path.cwd()\n",
    "    while cur != cur.parent:  # 防止無限迴圈，到達檔案系統根目錄就停\n",
    "        if (cur / marker).exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return None\n",
    "\n",
    "def import_data_from_github():\n",
    "    import urllib.request, shutil\n",
    "    \n",
    "    def isRunningInColab() -> bool:\n",
    "        return \"google.colab\" in sys.modules\n",
    "\n",
    "    def isRunningInJupyterLab() -> bool:\n",
    "        try:\n",
    "            import jupyterlab\n",
    "            return True\n",
    "        except ImportError:\n",
    "            return False\n",
    "        \n",
    "    def detect_env():\n",
    "        from IPython import get_ipython\n",
    "        if isRunningInColab():\n",
    "            return \"Colab\"\n",
    "        elif isRunningInJupyterLab():\n",
    "            return \"JupyterLab\"\n",
    "        elif \"notebook\" in str(type(get_ipython())).lower():\n",
    "            return \"Jupyter Notebook\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "    def get_utils_dir(env): \n",
    "        if env == \"Colab\": \n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return \"/content/utils\"\n",
    "        else:\n",
    "            return Path.cwd() / \"utils\"\n",
    "\n",
    "    def get_data_dir(env): \n",
    "        if env == \"Colab\": \n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return \"/content/data\"\n",
    "        else:\n",
    "            return Path.cwd() / \"data\"\n",
    "\n",
    "    def get_images_dir(env): \n",
    "        if env == \"Colab\": \n",
    "            if \"/content\" not in sys.path:\n",
    "                sys.path.insert(0, \"/content\")\n",
    "            return f\"/content/images\"\n",
    "        else:\n",
    "            return Path.cwd() / \"images\"\n",
    "\n",
    "    env = detect_env()\n",
    "    UTILS_DIR = get_utils_dir(env)\n",
    "    DATA_DIR = get_data_dir(env)\n",
    "    IMG_DIR = get_images_dir(env)\n",
    "\n",
    "    REPO_DIR = \"Machine-Learning-Lab\"\n",
    "\n",
    "    #shutil.rmtree(UTILS_DIR, ignore_errors=True)\n",
    "    os.makedirs(UTILS_DIR, exist_ok=True)\n",
    "    #shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "    BASE = f\"https://raw.githubusercontent.com/mz038197/{REPO_DIR}/main\"\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/lab_utils_multi.py\", f\"{UTILS_DIR}/lab_utils_multi.py\")\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/lab_utils_common.py\", f\"{UTILS_DIR}/lab_utils_common.py\")\n",
    "    urllib.request.urlretrieve(f\"{BASE}/utils/deeplearning.mplstyle\", f\"{UTILS_DIR}/deeplearning.mplstyle\")\n",
    "    urllib.request.urlretrieve(f\"{BASE}/data/houses.txt\", f\"{DATA_DIR}/houses.txt\")\n",
    "\n",
    "    images_list = [\"shortRun.PNG\", \"longRun.PNG\", \"scale.PNG\"]\n",
    "    for image in images_list:\n",
    "        urllib.request.urlretrieve(f\"{BASE}/lab/teacher/Regression/images/{image}\", f\"{IMG_DIR}/{image}\")\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "\n",
    "if repo_root is None:\n",
    "    import_data_from_github()\n",
    "    repo_root = Path.cwd()\n",
    "    \n",
    "os.chdir(repo_root)\n",
    "print(f\"✅ 切換工作目錄至 {Path.cwd()}\")\n",
    "sys.path.append(str(repo_root)) if str(repo_root) not in sys.path else None\n",
    "print(f\"✅ 加入到系統路徑\")\n",
    "\n",
    "from utils.lab_utils_multi import  load_house_data, run_gradient_descent \n",
    "from utils.lab_utils_multi import  norm_plot, plt_equal_scale, plot_cost_i_w\n",
    "from utils.lab_utils_common import dlc\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.style.use('utils/deeplearning.mplstyle')\n",
    "print(\"✅ 匯入模組及設定繪圖樣式\")\n",
    "#endregion 資料載入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c71614",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe570ee",
   "metadata": {},
   "source": [
    "## 符號說明（Notation）\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| 一般符號 | 說明 | Python（若適用） |\n",
    "| ------------| ------------------------------------------------------------|----------------|\n",
    "| $a$ | 標量（scalar），非粗體 |\n",
    "| $\\mathbf{a}$ | 向量（vector），粗體小寫 |\n",
    "| $\\mathbf{A}$ | 矩陣（matrix），粗體大寫 |\n",
    "| **Regression（迴歸）** |  |  |\n",
    "| $\\mathbf{X}$ | 訓練樣本矩陣 | `X_train` |   \n",
    "| $\\mathbf{y}$ | 訓練樣本目標值 | `y_train` |\n",
    "| $\\mathbf{x}^{(i)}$, $y^{(i)}$ | 第 $i$ 筆訓練樣本 | `X[i]`, `y[i]`|\n",
    "| m | 訓練樣本數 | `m`|\n",
    "| n | 每筆樣本的特徵數 | `n`|\n",
    "| $\\mathbf{w}$ | 參數：權重（weights） | `w` |\n",
    "| $b$ | 參數：偏差（bias） | `b` |     \n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | 在樣本 $\\mathbf{x}^{(i)}$ 上，由參數 $\\mathbf{w},b$ 所計算出的模型輸出：$f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$ | `f_wb` | \n",
    "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$| 成本函數對參數 $w_j$ 的偏導數（梯度） |`dj_dw[j]`| \n",
    "|$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$| 成本函數對參數 $b$ 的偏導數（梯度）| `dj_db`|\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa4189",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74795f00",
   "metadata": {},
   "source": [
    "# 問題說明（Problem Statement）\n",
    "\n",
    "與先前的實驗一樣，我們會以房價預測作為例子。訓練資料集中包含許多筆樣本，每筆樣本有 4 個特徵（面積、臥室數、樓層數、屋齡），如下面的表格所示。請注意，在本實驗中，面積（Size）使用的是「平方英尺（sqft）」為單位，而在較早的實驗中使用的是「以 1000 平方英尺為單位」。此外，這個資料集比前一個實驗使用的還要大。\n",
    "\n",
    "我們希望利用這些特徵建立一個線性迴歸模型，之後就能用它來預測其他房屋的價格──例如：一棟 1200 平方英尺、3 間臥室、1 層樓、屋齡 40 年的房子。\n",
    "\n",
    "## 資料集（Dataset）\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| 面積（Size, sqft） | 臥室數（Number of Bedrooms） | 樓層數（Number of floors） | 屋齡（Age of Home） | 價格（千美元, Price） |\n",
    "| -------------------|------------------------------|---------------------------|---------------------|------------------------|\n",
    "| 952                | 2                            | 1                         | 65                  | 271.5                  |\n",
    "| 1244               | 3                            | 2                         | 64                  | 232                    |\n",
    "| 1947               | 3                            | 2                         | 17                  | 509.8                  |\n",
    "| ...                | ...                          | ...                       | ...                 | ...                    |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023144be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X_train, y_train = load_house_data()\n",
    "X_features = ['size(sqft)','bedrooms','floors','age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d7890",
   "metadata": {},
   "source": [
    "讓我們將每個特徵與房價繪圖，來看看資料集與各個特徵的關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956858f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"Price (1000's)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210fe3a",
   "metadata": {},
   "source": [
    "將每一個特徵與目標值（房價）畫在一起，可以幫助我們判斷哪些特徵對價格的影響較大。上面的圖中可以看到：房屋面積愈大，價格通常愈高；臥室數與樓層數看起來對價格的影響並不那麼明顯；而較新的房子通常比老舊房子有更高的價格。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b004b",
   "metadata": {},
   "source": [
    "<a name=\"toc_15456_5\"></a>\n",
    "## 多變量梯度下降（Gradient Descent With Multiple Variables）\n",
    "下面是你在上一個「多變量梯度下降」實驗中推導出的公式：\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\\;\n",
    "& w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j = 0..n-1}\\newline\n",
    "&b\\ \\ := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "\n",
    "其中，n 是特徵的數量，參數 $w_j$ 與 $b$ 會同時被更新，而\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{2}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "* m 是資料集中訓練樣本的數量\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ 是模型在樣本 $\\mathbf{x}^{(i)}$ 上的預測值，而 $y^{(i)}$ 則是對應的目標值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de4eb4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d426abd",
   "metadata": {},
   "source": [
    "## 學習率（Learning Rate）\n",
    "\n",
    "在課程中，我們討論了與設定學習率 $\\alpha$ 相關的一些問題。學習率會控制每次更新參數時的步伐大小（請參考上面的式子 (1)），而且是**所有參數共用同一個值**。  \n",
    "\n",
    "接下來，我們就在這個資料集上執行梯度下降，並嘗試幾種不同的 $\\alpha$ 設定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b441cd04",
   "metadata": {},
   "source": [
    "### $\\alpha$ = 9.9e-7（學習率較大時的行為）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha to 9.9e-7\n",
    "_, _, hist = run_gradient_descent(X_train, y_train, 10, alpha = 9.9e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942bc4a8",
   "metadata": {},
   "source": [
    "看起來學習率設定得太高了，解並沒有收斂，成本函數的值反而在「上升」而不是下降。讓我們把結果畫出來看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d59b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55e9de",
   "metadata": {},
   "source": [
    "右邊的圖顯示其中一個參數 $w_0$ 的變化情形。在每一次迭代中，它都「超過」最佳值太多，導致成本不但沒有往最小值靠近，反而持續上升。請注意，這個圖並不是完整的真實情況，因為實際上每一次更新有 4 個參數同時在改變，而圖中只顯示 $w_0$，其他參數則固定在較溫和的數值上。在這張圖以及後面幾張圖中，你可能會注意到藍色與橘色的曲線有些微偏差，這是因為它只是高維情況的一個投影。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91e774",
   "metadata": {},
   "source": [
    "\n",
    "### $\\alpha$ = 9e-7\n",
    "讓我們把學習率再調小一點，看看會發生什麼事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha to 9e-7\n",
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 9e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b902c",
   "metadata": {},
   "source": [
    "在整個訓練過程中，成本都在持續下降，顯示這個 alpha 值並不算太大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train, y_train, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e2aaa",
   "metadata": {},
   "source": [
    "左圖中可以看到，成本確實如預期般地在下降。右圖中則可以看到 $w_0$ 仍然在最小值附近來回震盪，不過每一次迭代時，成本仍然持續下降而不是上升。注意上方圖中，`dj_dw[0]` 在每次迭代時都會改變符號，代表 `w[0]` 持續在最佳值的兩側跳動。\n",
    "這個 alpha 值最終會收斂，你可以嘗試改變迭代次數來觀察它的行為。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b2f7b1",
   "metadata": {},
   "source": [
    "### $\\alpha$ = 1e-7\n",
    "我們再把 $\\alpha$ 調得更小一些，來看看結果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8203dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha to 1e-7\n",
    "_,_,hist = run_gradient_descent(X_train, y_train, 10, alpha = 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5a692",
   "metadata": {},
   "source": [
    "在整個訓練過程中，成本持續下降，顯示這個 $\\alpha$ 值同樣不算太大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_i_w(X_train,y_train,hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc53814",
   "metadata": {},
   "source": [
    "左圖中可以看到，成本如預期持續下降。右圖則顯示 $w_0$ 在沒有明顯震盪的情況下逐漸逼近最小值，且在整個訓練過程中，`dj_w0` 都維持為負值。這樣的設定同樣會收斂。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8792a492",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49cccd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 特徵縮放（Feature Scaling）\n",
    "\n",
    "課程中說明了，將資料集中的各個特徵重新縮放到「相近的數值範圍」是非常重要的。\n",
    "\n",
    "如果你想更深入了解為什麼要這麼做，可以展開下方的「Details」區塊；若暫時不需要細節，往下的內容會示範如何實作特徵縮放。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b6eeb",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size='3', color='darkgreen'><b>Details</b></font>\n",
    "</summary>\n",
    "\n",
    "讓我們再次回頭看看 $\\alpha$ = 9e-7 的情況。這個值非常接近在不發散的前提下所能設定的最大值。下面這張圖是只跑前幾次迭代的「短程訓練」結果：\n",
    "\n",
    "<figure>\n",
    "    <img src=\"./images/shortRun.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "\n",
    "可以看到，雖然成本正在下降，但很明顯由於梯度較大，$w_0$ 比其他參數前進得快得多。\n",
    "\n",
    "下一張圖顯示的是使用 $\\alpha$ = 9e-7、跑了非常久（需要好幾個小時）的「長程訓練」結果：\n",
    "\n",
    "<figure>\n",
    "    <img src=\"./images/longRun.PNG\" style=\"width:1200px;\" >\n",
    "</figure>\n",
    "    \n",
    "從圖中可以看到，成本在最初快速下降之後，後續的下降速度就變得非常緩慢。請留意 `w0` 與 `w1`,`w2`,`w3` 之間的差異，以及 `dj_dw0` 與 `dj_dw1-3` 的差異：`w0` 很快就接近最後的值，而 `dj_dw0` 也迅速下降到很小的數值，代表 `w0` 已經接近最終解；相比之下，其他參數的變化就慢得多。\n",
    "\n",
    "為什麼會這樣？有什麼可以改進的嗎？請看下面這張圖：\n",
    "<figure>\n",
    "    <center> <img src=\"./images/scale.PNG\"   ></center>\n",
    "</figure>   \n",
    "\n",
    "這張圖說明了為什麼各個 $w$ 的更新速度會差這麼多：\n",
    "- $\\alpha$ 是所有參數（$w$ 和 $b$）共用的。\n",
    "- 對 $w$ 而言，更新時會把共同的誤差項乘上對應的特徵值（而 $b$ 則不會乘上特徵）。\n",
    "- 各個特徵的數值尺度差距很大，使得某些特徵對應的參數更新得比其他參數快很多。例如，$w_0$ 乘上的特徵是 `size(sqft)`，通常大於 1000，而 $w_1$ 乘上的特徵是 `number of bedrooms`，通常只在 2–4 之間。 \n",
    "    \n",
    "解決方法就是「特徵縮放（Feature Scaling）」。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26756c",
   "metadata": {},
   "source": [
    "課程中介紹了三種不同的技巧：\n",
    "\n",
    "- **Feature scaling（特徵縮放）**：基本做法是將每個「非負」特徵除以其最大值，或更一般地，使用 (x-min)/(max-min) 來根據最小值與最大值重新縮放。兩種方式都可以把特徵縮放到大約 -1 到 1 的範圍；前者適用於全為正值的特徵、實作簡單，後者則較通用，適用於任意特徵。\n",
    "\n",
    "- **Mean normalization（平均值正規化）**：$x_i := \\dfrac{x_i - \\mu_i}{\\max - \\min}$ \n",
    "\n",
    "- **Z-score normalization（z 分數正規化）**：這是我們接下來要實作與探討的重點。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74411f89",
   "metadata": {},
   "source": [
    "\n",
    "### z-score 正規化（z-score normalization）\n",
    "在進行 z-score 正規化之後，所有特徵都會有平均值 0，且標準差為 1。\n",
    "\n",
    "要實作 z-score 正規化，可以依照下列公式調整輸入值：\n",
    "$$x^{(i)}_j = \\dfrac{x^{(i)}_j - \\mu_j}{\\sigma_j} \\tag{4}$$ \n",
    "其中，$j$ 表示在矩陣 $\\mathbf{X}$ 中選取的特徵或欄位；$\\mu_j$ 是第 $j$ 個特徵在所有樣本中的平均值，$\\sigma_j$ 則是第 $j$ 個特徵的標準差。\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} x^{(i)}_j \\tag{5}\\\\\n",
    "\\sigma^2_j &= \\frac{1}{m} \\sum_{i=0}^{m-1} (x^{(i)}_j - \\mu_j)^2  \\tag{6}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    ">**實作說明（Implementation Note）：** 在做特徵正規化時，必須記錄下用來正規化的那些數值──也就是每一個特徵的平均值與標準差。完成模型訓練並學得參數之後，我們通常會用它來預測訓練資料中沒出現過的房屋價格。對於新的輸入 x（例如客廳面積與臥室數），在帶入模型之前，必須先用「訓練資料計算出來的平均值與標準差」來對 x 做同樣的正規化。\n",
    "\n",
    "**實作（Implementation）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22fefb",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d6f63eca66d5629",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def zscore_normalize_features(X):\n",
    "    \"\"\"\n",
    "    computes  X, zcore normalized by column\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : input data, m examples, n features\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): input normalized by column\n",
    "      mu (ndarray (n,))     : mean of each feature\n",
    "      sigma (ndarray (n,))  : standard deviation of each feature\n",
    "    \"\"\"\n",
    "    # find the mean of each column/feature\n",
    "    mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "    # find the standard deviation of each column/feature\n",
    "    sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "    # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)\n",
    " \n",
    "#check our work\n",
    "#from sklearn.preprocessing import scale\n",
    "#scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f751ee59",
   "metadata": {},
   "source": [
    "接下來我們來看看 z-score 正規化的各個步驟。下圖會一步步顯示特徵在正規化前、中、後的變化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu     = np.mean(X_train,axis=0)   \n",
    "sigma  = np.std(X_train,axis=0) \n",
    "X_mean = (X_train - mu)\n",
    "X_norm = (X_train - mu)/sigma      \n",
    "\n",
    "fig,ax=plt.subplots(1, 3, figsize=(12, 3))\n",
    "ax[0].scatter(X_train[:,0], X_train[:,3])\n",
    "ax[0].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[0].set_title(\"unnormalized\")\n",
    "ax[0].axis('equal')\n",
    "\n",
    "ax[1].scatter(X_mean[:,0], X_mean[:,3])\n",
    "ax[1].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[1].set_title(r\"X - $\\mu$\")\n",
    "ax[1].axis('equal')\n",
    "\n",
    "ax[2].scatter(X_norm[:,0], X_norm[:,3])\n",
    "ax[2].set_xlabel(X_features[0]); ax[0].set_ylabel(X_features[3]);\n",
    "ax[2].set_title(r\"Z-score normalized\")\n",
    "ax[2].axis('equal')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.suptitle(\"distribution of features before, during, after normalization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40a28b7",
   "metadata": {},
   "source": [
    "上面的圖顯示訓練集中兩個參數「age」與「size(sqft)」之間的關係，且 *兩個軸使用相同尺度*：\n",
    "- 左圖（Unnormalized）：尚未正規化時，`size(sqft)` 的數值範圍或變異遠大於 `age`。\n",
    "- 中圖（X − μ）：第一步是從每個特徵中減去其平均值，讓特徵大致以 0 為中心。對 `age` 來說變化不太明顯，但可以明顯看到 `size(sqft)` 已經移到 0 附近。\n",
    "- 右圖（Z-score normalized）：第二步再除以標準差，讓兩個特徵都以 0 為中心，且具有相近的尺度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691ea33",
   "metadata": {},
   "source": [
    "接著，我們將整個資料集做正規化，並與原始資料做比較。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the original features\n",
    "X_norm, X_mu, X_sigma = zscore_normalize_features(X_train)\n",
    "print(f\"X_mu = {X_mu}, \\nX_sigma = {X_sigma}\")\n",
    "print(f\"Peak to Peak range by column in Raw        X:{np.ptp(X_train,axis=0)}\")   \n",
    "print(f\"Peak to Peak range by column in Normalized X:{np.ptp(X_norm,axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458fac4",
   "metadata": {},
   "source": [
    "可以看到，每一個欄位（特徵）的「峰到峰範圍」（最大值減最小值）從原本相差上千的尺度，經過正規化之後，縮小到大約 2–3 的範圍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11553aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_train[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"count\");\n",
    "fig.suptitle(\"distribution of features before normalization\")\n",
    "plt.show()\n",
    "fig,ax=plt.subplots(1,4,figsize=(12,3))\n",
    "for i in range(len(ax)):\n",
    "    norm_plot(ax[i],X_norm[:,i],)\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "ax[0].set_ylabel(\"count\"); \n",
    "fig.suptitle(\"distribution of features after normalization\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e57ad",
   "metadata": {},
   "source": [
    "請注意，上圖中正規化後的資料（x 軸）大致以 0 為中心，範圍約在 ±2 之間；更重要的是，各個特徵的範圍現在彼此之間相當接近。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e71f4",
   "metadata": {},
   "source": [
    "接下來，我們使用正規化後的資料重新執行梯度下降演算法。\n",
    "請注意，這次我們可以使用**大非常多的 alpha 值**，這會大幅加快梯度下降的收斂速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_norm, b_norm, hist = run_gradient_descent(X_norm, y_train, 1000, 1.0e-1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafd582",
   "metadata": {},
   "source": [
    "使用經過縮放的特徵後，可以在**短得多的時間內**獲得非常精確的結果！你會發現，在這段相對短的訓練過程結束時，每一個參數的梯度都已經非常小。對於使用正規化特徵的線性迴歸而言，學習率設為 0.1 是一個不錯的起點。\n",
    "\n",
    "接著，我們將預測值與目標值畫在一起。請注意：模型實際做預測時用的是「正規化後的特徵」，但繪圖時 x 軸仍顯示「原始的特徵值」，方便解讀。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict target using normalized features\n",
    "m = X_norm.shape[0]\n",
    "yp = np.zeros(m)\n",
    "for i in range(m):\n",
    "    yp[i] = np.dot(X_norm[i], w_norm) + b_norm\n",
    "\n",
    "    # plot predictions and targets versus original features    \n",
    "fig,ax=plt.subplots(1,4,figsize=(12, 3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train[:,i],y_train, label = 'target')\n",
    "    ax[i].set_xlabel(X_features[i])\n",
    "    ax[i].scatter(X_train[:,i],yp,color=dlc[\"dlorange\"], label = 'predict')\n",
    "ax[0].set_ylabel(\"Price\"); ax[0].legend();\n",
    "fig.suptitle(\"target versus prediction using z-score normalized model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a357c625",
   "metadata": {},
   "source": [
    "結果看起來相當不錯。這裡有幾點需要特別注意：\n",
    "- 當特徵維度超過一個時，無法只用一張圖就把「結果 vs. 特徵」完整呈現出來。\n",
    "- 在產生這些圖時，實際預測是使用「正規化後的特徵」計算出來的；凡是使用從正規化訓練集學得之參數所做的預測，其輸入特徵也都必須先做相同的正規化處理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1284bfa",
   "metadata": {},
   "source": [
    "**預測（Prediction）**\n",
    "我們建立這個模型的目的，就是要用它來預測資料集中「沒有出現過」的房屋價格。現在來預測一棟房子的價格，其條件為：1200 平方英尺、3 間臥室、1 層樓、屋齡 40 年。請記得，必須使用在訓練資料做正規化時所計算出的平均值與標準差，先對這筆輸入做正規化，再帶入模型進行預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, normalize out example.\n",
    "x_house = np.array([1200, 3, 1, 40])\n",
    "x_house_norm = (x_house - X_mu) / X_sigma\n",
    "print(x_house_norm)\n",
    "x_house_predict = np.dot(x_house_norm, w_norm) + b_norm\n",
    "print(f\" predicted price of a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old = ${x_house_predict*1000:0.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee8e12",
   "metadata": {},
   "source": [
    "**成本等高線（Cost Contours）**  \n",
    "\n",
    "另一種理解特徵縮放的方法，是從「成本函數的等高線圖」來觀察。當各特徵的尺度不一致時，在參數空間中繪製的成本等高線會呈現非常不對稱的形狀。\n",
    "\n",
    "在下圖中，參數的尺度已經過調整：左圖是在**未正規化特徵**的狀況下，以 w[0]（對應平方英尺）與 w[1]（對應臥室數）為軸畫出的成本等高線。由於尺度嚴重不對稱，等高線被拉得又長又扁，幾乎看不到完整的封閉曲線。相反地，在右圖中，當特徵經過正規化後，成本等高線就對稱得多。這代表在梯度下降的過程中，各個參數可以比較均衡地朝最小值前進，每個方向都能取得類似的進展。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_equal_scale(X_train, X_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a566d08a",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c611b",
   "metadata": {},
   "source": [
    "\n",
    "## 恭喜！（Congratulations）\n",
    "在本實驗中，你已經：\n",
    "- 使用你在先前實驗中為「多特徵線性迴歸」所撰寫的各種函式\n",
    "- 探索了學習率 $\\alpha$ 對收斂行為的影響\n",
    "- 了解了利用 z-score 正規化進行特徵縮放，能大幅加速梯度下降的收斂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4e16d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a8b10",
   "metadata": {},
   "source": [
    "## 感謝（Acknowledgments）\n",
    "本實驗所使用的房價資料，是取自 Dean De Cock 為資料科學教育整理的 [Ames Housing 資料集](http://jse.amstat.org/v19n3/decock.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd4d25",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
