{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optional Lab - Neurons and Layers (PyTorch Version)\n",
        "In this lab we will explore the inner workings of neurons/units and layers. In particular, the lab will draw parallels to the models you have mastered in Course 1, the regression/linear model and the logistic model. The lab will introduce PyTorch and demonstrate how these models are implemented in that framework.\n",
        "<figure>\n",
        "   <img src=\"./images/C2_W1_NeuronsAndLayers.png\"  style=\"width:540px;height:200px;\" >\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Packages\n",
        "**PyTorch**  \n",
        "PyTorch is an open-source machine learning framework developed by Facebook's AI Research lab. This course will be using PyTorch instead of TensorFlow/Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#region 資料載入\n",
        "def find_repo_root(marker=\"README.md\"):\n",
        "    cur = Path.cwd()\n",
        "    while cur != cur.parent:  # 防止無限迴圈，到達檔案系統根目錄就停\n",
        "        if (cur / marker).exists():\n",
        "            return cur\n",
        "        cur = cur.parent\n",
        "    return None\n",
        "\n",
        "def import_data_from_github():\n",
        "    import urllib.request, shutil\n",
        "    \n",
        "    def isRunningInColab() -> bool:\n",
        "        return \"google.colab\" in sys.modules\n",
        "\n",
        "    def isRunningInJupyterLab() -> bool:\n",
        "        try:\n",
        "            import jupyterlab\n",
        "            return True\n",
        "        except ImportError:\n",
        "            return False\n",
        "        \n",
        "    def detect_env():\n",
        "        from IPython import get_ipython\n",
        "        if isRunningInColab():\n",
        "            return \"Colab\"\n",
        "        elif isRunningInJupyterLab():\n",
        "            return \"JupyterLab\"\n",
        "        elif \"notebook\" in str(type(get_ipython())).lower():\n",
        "            return \"Jupyter Notebook\"\n",
        "        else:\n",
        "            return \"Unknown\"\n",
        "        \n",
        "    def get_utils_dir(env): \n",
        "        if env == \"Colab\": \n",
        "            if \"/content\" not in sys.path:\n",
        "                sys.path.insert(0, \"/content\")\n",
        "            return \"/content/utils\"\n",
        "        else:\n",
        "            return Path.cwd() / \"utils\"\n",
        "\n",
        "    def get_data_dir(env): \n",
        "        if env == \"Colab\": \n",
        "            if \"/content\" not in sys.path:\n",
        "                sys.path.insert(0, \"/content\")\n",
        "            return \"/content/data\"\n",
        "        else:\n",
        "            return Path.cwd() / \"data\"\n",
        "\n",
        "    def get_images_dir(env): \n",
        "        if env == \"Colab\": \n",
        "            if \"/content\" not in sys.path:\n",
        "                sys.path.insert(0, \"/content\")\n",
        "            return f\"/content/images\"\n",
        "        else:\n",
        "            return Path.cwd() / \"images\"\n",
        "\n",
        "    env = detect_env()\n",
        "    UTILS_DIR = get_utils_dir(env)\n",
        "    os.makedirs(UTILS_DIR, exist_ok=True)\n",
        "\n",
        "    REPO_DIR = \"Machine-Learning-Lab\"\n",
        "    BASE = f\"https://raw.githubusercontent.com/mz038197/{REPO_DIR}/main\"\n",
        "    for file in [\"lab_utils_common_nn.py\", \"lab_neurons_utils.py\", \"deeplearning.mplstyle\"]:\n",
        "        urllib.request.urlretrieve(f\"{BASE}/utils/{file}\", f\"{UTILS_DIR}/{file}\")\n",
        "\n",
        "repo_root = find_repo_root()\n",
        "\n",
        "if repo_root is None:\n",
        "    import_data_from_github()\n",
        "    repo_root = Path.cwd()\n",
        "    \n",
        "os.chdir(repo_root)\n",
        "print(f\"✅ 切換工作目錄至 {Path.cwd()}\")\n",
        "sys.path.append(str(repo_root)) if str(repo_root) not in sys.path else None\n",
        "print(f\"✅ 加入到系統路徑\")\n",
        "\n",
        "from utils.lab_utils_common_nn import dlc\n",
        "from utils.lab_neurons_utils import plt_prob_1d, sigmoidnp, plt_linear, plt_logistic\n",
        "plt.style.use('utils/deeplearning.mplstyle')\n",
        "\n",
        "# 設定隨機種子以便重現結果\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "print(\"✅ 匯入模組及設定繪圖樣式\")\n",
        "#endregion 資料載入"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neuron without activation - Regression/Linear Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataSet\n",
        "We'll use an example from Course 1, linear regression on house prices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = np.array([[1.0], [2.0]], dtype=np.float32)\n",
        "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)\n",
        "\n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Data Points\")\n",
        "ax.legend( fontsize='xx-large')\n",
        "ax.set_ylabel('Price (in 1000s of dollars)', fontsize='xx-large')\n",
        "ax.set_xlabel('Size (1000 sqft)', fontsize='xx-large')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression/Linear Model \n",
        "The function implemented by a neuron with no activation is the same as in Course 1, linear regression:\n",
        "$$ f_{\\mathbf{w},b}(x^{(i)}) = \\mathbf{w}\\cdot x^{(i)} + b \\tag{1}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can define a layer with one neuron or unit and compare it to the familiar linear regression function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch 中使用 nn.Linear 來建立線性層\n",
        "linear_layer = nn.Linear(in_features=1, out_features=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine the weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 在 PyTorch 中，權重在建立時就會初始化\n",
        "print(f\"w = {linear_layer.weight.data.numpy()}, b = {linear_layer.bias.data.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The weights are initialized randomly. Let's try the model on one example in `X_train`. Note, the input must be a PyTorch tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 將 numpy array 轉換為 PyTorch tensor\n",
        "X_tensor = torch.from_numpy(X_train[0].reshape(1,1))\n",
        "with torch.no_grad():\n",
        "    a1 = linear_layer(X_tensor)\n",
        "print(a1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is a tensor with a shape of (1,1) or one entry.   \n",
        "Now let's look at the weights and bias. Let's set them to some known values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_w = np.array([[200]], dtype=np.float32)\n",
        "set_b = np.array([100], dtype=np.float32)\n",
        "\n",
        "# 在 PyTorch 中設定權重和偏差\n",
        "linear_layer.weight.data = torch.from_numpy(set_w)\n",
        "linear_layer.bias.data = torch.from_numpy(set_b)\n",
        "\n",
        "print(f\"w = {linear_layer.weight.data.numpy()}, b = {linear_layer.bias.data.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare equation (1) to the layer output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    a1 = linear_layer(X_tensor)\n",
        "print(a1)\n",
        "alin = np.dot(set_w, X_train[0].reshape(1,1)) + set_b\n",
        "print(alin)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They produce the same values!\n",
        "Now, we can use our linear layer to make predictions on our training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用 PyTorch 模型進行預測\n",
        "X_train_tensor = torch.from_numpy(X_train)\n",
        "with torch.no_grad():\n",
        "    prediction_torch = linear_layer(X_train_tensor).numpy()\n",
        "\n",
        "# 使用 NumPy 進行預測\n",
        "prediction_np = np.dot(X_train, set_w.T) + set_b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt_linear(X_train, Y_train, prediction_torch, prediction_np)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neuron with Sigmoid activation\n",
        "The function implemented by a neuron/unit with a sigmoid activation is the same as in Course 1, logistic  regression:\n",
        "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
        "where $$g(x) = sigmoid(x)$$ \n",
        "\n",
        "Let's set $w$ and $b$ to some known values and check the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataSet\n",
        "We'll use an example from Course 1, logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)\n",
        "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos = Y_train == 1\n",
        "neg = Y_train == 0\n",
        "\n",
        "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
        "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
        "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
        "              edgecolors=dlc[\"dlblue\"],lw=3)\n",
        "\n",
        "ax.set_ylim(-0.08,1.1)\n",
        "ax.set_ylabel('y', fontsize=12)\n",
        "ax.set_xlabel('x', fontsize=12)\n",
        "ax.set_title('one variable plot')\n",
        "ax.legend(fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Neuron\n",
        "We can implement a 'logistic neuron' by adding a sigmoid activation. The function of the neuron is then described by (2) above.   \n",
        "This section will create a PyTorch Model that contains our logistic layer to demonstrate an alternate method of creating models. PyTorch is most often used to create multi-layer models. The [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) model is a convenient means of constructing these models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用 Sequential 建立模型\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the model structure. There is only one layer in this model and that layer has only one unit. The unit has two parameters, $w$ and $b$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model)\n",
        "print(\"\\nModel parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"{name}: {param.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 獲取第一層（Linear layer）\n",
        "logistic_layer = model[0]\n",
        "w = logistic_layer.weight.data.numpy()\n",
        "b = logistic_layer.bias.data.numpy()\n",
        "print(w, b)\n",
        "print(w.shape, b.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's set the weight and bias to some known values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "set_w = np.array([[2]], dtype=np.float32)\n",
        "set_b = np.array([-4.5], dtype=np.float32)\n",
        "\n",
        "# 設定權重\n",
        "logistic_layer.weight.data = torch.from_numpy(set_w)\n",
        "logistic_layer.bias.data = torch.from_numpy(set_b)\n",
        "\n",
        "print(f\"w = {logistic_layer.weight.data.numpy()}, b = {logistic_layer.bias.data.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare equation (2) to the layer output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = torch.from_numpy(X_train[0].reshape(1,1))\n",
        "with torch.no_grad():\n",
        "    a1 = model(X_test).numpy()\n",
        "print(a1)\n",
        "\n",
        "alog = sigmoidnp(np.dot(set_w, X_train[0].reshape(1,1)) + set_b)\n",
        "print(alog)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "They produce the same values!\n",
        "Now, we can use our logistic layer and NumPy model to make predictions on our training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 創建一個包裝函數以便與繪圖工具相容\n",
        "class ModelWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X_tensor = torch.from_numpy(X.astype(np.float32))\n",
        "        with torch.no_grad():\n",
        "            return self.model(X_tensor).numpy()\n",
        "\n",
        "wrapped_model = ModelWrapper(model)\n",
        "plt_logistic(X_train, Y_train, wrapped_model, set_w, set_b, pos, neg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The shading above reflects the output of the sigmoid which varies from 0 to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Congratulations!\n",
        "You built a very simple neural network using PyTorch and have explored the similarities of a neuron to the linear and logistic regression from Course 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
