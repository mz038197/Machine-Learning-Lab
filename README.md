# **監督式機器學習：迴歸與分類**

## **上課講義**

### **Part1 : Regression**
1. **機器學習導論 (Introduction)**<br>
        [ [講義](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/01_Introduction.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/EINTP6) ]

2. **模型表示 (Model Representation)**<br>
        [ [講義](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/02_Model_Representation.ipynb) ]

3. **線性迴歸的成本函數 (Cost Function for Linear Regression)**<br>
        [ [講義](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/03_Cost_Function_for_Linear_Regression.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/16YITA) ]

4. **線性迴歸的梯度下降 (Gradient Descent for Linear Regression)**<br>
        [ [講義](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/04_Gradient_Descent_for_Linear_Regression.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/F263LV) ]

5. **多輸入特徵的線性迴歸 (Linear Regression with Multiple Variables)**<br>
* 向量化 :&nbsp;[ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/05_Vectorization.ipynb) ]

* 多特徵線性迴歸 :&nbsp;[ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Regression/06_Multiple_Variable.ipynb) ]

* 章節測驗 :&nbsp;[ [連結](https://quizzes.vanscoding.com/quiz/M7ZLQP) ]

### **Part2 : Classification**
1. **分類 (Classification)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/01_Classification.ipynb) ]

2. **S形函數 (Sigmoid Function)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/02_Sigmoid_Function.ipynb) ]

3. **決策邊界 (Decision Boundary)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/03_Decision_Boundary.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/9INCST) ]

4. **邏輯迴歸損失函數 (Logistic Loss)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/04_Logistic_Loss.ipynb) ]

5. **邏輯回歸的成本函數 (Cost Function for Logistic Regression)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/05_Cost_Function_for_Logistic_Regression.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/LZDF1G) ]

6. **邏輯迴歸的梯度下降 (Gradient Descent for Logistic Regression)**<br>
        [ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/06_Gradient_Descent_for_Logistic_Regression.ipynb) ]
        &nbsp;
        [ [測驗](https://quizzes.vanscoding.com/quiz/FJL7Y3) ]

7. **套用正則化解決過度擬合問題 (Regularization to Reduce Overfitting)**<br>
* 過度擬合 :&nbsp;[ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/08_Overfitting.ipynb) ]

* 正則化 :&nbsp;[ [實驗室](https://colab.research.google.com/github/mz038197/Machine-Learning/blob/main/lab/teacher/Classification/09_Regularization.ipynb) ]

* 章節測驗 :&nbsp;[ [連結](https://quizzes.vanscoding.com/quiz/2PN4K0) ]